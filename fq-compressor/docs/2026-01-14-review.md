# fq-compressor 设计方案评估报告

**评估日期**: 2026-01-14  
**评估范围**: 架构设计、格式定义、实现计划、技术选型

---

## 执行摘要

fq-compressor 是一个有野心的 FASTQ 压缩工具项目，整体设计思路清晰，技术选型合理，参考项目选择得当。设计文档质量高，展现了对领域的深入理解。

**主要优势**:
- 清晰的分层架构（CLI → Core → Pipeline → Storage）
- 合理的技术栈选择（C++20, TBB, CLI11, Quill）
- 充分的参考项目研究（Spring, fqzcomp5, pigz 等）
- 完善的测试策略（单元测试 + 属性测试）

**主要风险**:
1. **Spring 集成复杂度被低估** - 这是最大的技术风险
2. **Block-local ABC 的压缩率损失** - 需要明确量化
3. **格式设计存在小遗漏** - 容易修复但需要尽早处理

**总体评级**: ⭐⭐⭐⭐☆ (4/5)  
**建议**: 在正式开发前进行 2-3 天的技术 Spike，验证 Spring 集成可行性。

---

## 1. 架构层面的问题

### 1.1 Spring 集成的复杂度被低估 ⚠️ 高风险

**问题描述**:

Spring 的 ABC (Assembly-based Compression) 算法并非简单的"模块化"设计，它的核心流程是：

```
全局 Minimizer Index → 全局 Reordering → 全局 Consensus → 全局 Delta Encoding
```

设计文档计划将其改造为 **Block Context**（每 N 条 reads 重置状态），但这会带来以下问题：


#### 问题 1: 压缩率显著下降

- **原因**: Spring 的高压缩率依赖**全局重排序**。通过 Approximate Hamiltonian Path 算法，将相似的 reads 排列在一起，从而最大化局部共识（consensus）的覆盖范围。
- **影响**: Block 级别的局部重排会显著降低压缩效果，**预计损失 20-40% 压缩率**。
- **数据支持**: Spring 论文中提到，禁用全局重排序会导致压缩率从 ~0.3 bits/base 上升到 ~0.5 bits/base。

#### 问题 2: 改造工作量巨大

- **代码耦合度高**: Spring 的 `RefGen`, `Encoder`, `Decoder` 模块之间存在大量全局状态共享。
- **ResetContext() 实现困难**: 需要识别并重置所有全局状态（minimizer index, consensus buffer, arithmetic coder state 等）。
- **测试复杂度**: 需要确保改造后的算法在 Block 边界处不会产生压缩/解压不一致。

#### 问题 3: License 约束

- Spring 采用 **Non-commercial License**，这限制了项目的商业化可能性。
- 如果未来需要商业化，必须重新实现算法或寻求授权。

**建议方案**:


**方案 A: 双模式设计** (推荐)

```bash
# Fast Mode: Block-local ABC (支持随机访问)
fqc compress --mode fast --block-reads 10000 input.fq -o output.fqc

# Best Mode: 全局 ABC + 后置索引 (压缩率优先)
fqc compress --mode best input.fq -o output.fqc
```

- **Fast Mode**: 
  - Block 内独立压缩，支持 O(1) 随机访问
  - 压缩率: ~0.5-0.6 bits/base
  - 适用场景: 需要频繁随机访问的归档

- **Best Mode**: 
  - 全局 ABC，压缩后构建 Block Index（通过在压缩流中插入 Sync Marker）
  - 压缩率: ~0.3-0.4 bits/base
  - 随机访问: 需要从最近的 Sync Marker 开始解压（O(Block Size)）

**方案 B: 使用 Minicom 替代 Spring** (降级方案)

- Minicom 的算法更简单，更容易改造为 Block-local 模式
- 压缩率略低于 Spring，但仍优于传统方法
- 代码量更小，维护成本更低

**方案 C: 先实现 Baseline，再优化** (稳健方案)

1. **Phase 2a**: 使用 Zstd/LZMA 实现 Baseline（压缩率 ~1.5-2 bits/base）
2. **Phase 2b**: 验证框架、格式、流水线正确性
3. **Phase 2c**: 再尝试集成 Spring（如果失败，Baseline 仍可用）

---

### 1.2 随机访问与压缩率的 Trade-off 未明确 ⚠️ 中风险

**问题描述**:

设计文档中 "Scheme A" 假设 Block 独立压缩即可实现随机访问，但存在以下语义不清晰的问题：


#### 问题 1: Reordering 导致的顺序混乱

- 如果启用 `--reorder`（默认），解压后的 reads 顺序与原始文件不同
- `--range <start:end>` 的语义是"归档存储顺序"，这对用户可能不直观
- 用户期望的可能是"原始文件的第 X 到 Y 条 reads"

#### 问题 2: 缺少顺序映射

- 当前设计没有保存"原始顺序 → 归档顺序"的映射
- 如果用户需要提取"原始文件的第 1000-2000 条 reads"，无法实现

**建议方案**:

1. **在 GlobalHeader 中增加 Reorder Mapping**（可选）:
   ```cpp
   struct GlobalHeader {
       // ...
       bool has_reorder_map;  // 是否包含重排序映射
       uint64_t reorder_map_offset;  // 映射表偏移（如果有）
   };
   ```

2. **在 info 命令中显示顺序信息**:
   ```bash
   $ fqc info output.fqc
   Reordered: Yes
   Original Order Preserved: No
   Random Access Mode: Archive Order (use --show-mapping for details)
   ```

3. **在文档中明确说明**:
   - `--range` 的语义是"归档存储顺序"
   - 如果需要保留原始顺序，使用 `--preserve-order`（压缩率会降低）

---

### 1.3 内存管理策略不够具体 ⚠️ 中风险

**问题描述**:


设计文档提到"显式控制内存使用上限"，但没有具体策略：

- Spring 的 Minimizer Index 需要大量内存（~50 bytes/read）
- 如果 Block Size = 10K reads，每个 Block 需要 ~500KB 内存
- 如果并行度 = 16 threads，峰值内存 = 16 * 500KB = 8MB（可接受）
- 但如果 Block Size = 1M reads，峰值内存 = 16 * 50MB = 800MB（可能过高）

**建议方案**:

1. **增加内存预算配置**:
   ```bash
   fqc compress --memory-limit 4G --threads 16 input.fq
   ```
   自动调整 Block Size 和并行度以满足内存限制。

2. **在设计文档中明确内存模型**:
   ```
   Peak Memory = (Block Size * Bytes/Read * Parallelism) + Overhead
   Default: Block Size = 10K, Bytes/Read = 50, Parallelism = 16
   => Peak = 8MB + ~2MB (buffers) = 10MB
   ```

---

## 2. 格式设计的问题

### 2.1 BlockHeader 缺少关键字段 ⚠️ 高风险

**问题描述**:

当前 `BlockHeader` 定义：

```cpp
struct BlockHeader {
    uint32_t header_size;
    uint32_t block_id;
    uint8_t checksum_type;
    uint64_t block_xxhash64;
    uint32_t uncompressed_count;
    
    // Stream Offsets (Relative to Payload Start)
    uint32_t offset_id;
    uint32_t offset_seq;
    uint32_t offset_qual;
    uint32_t offset_aux;
    
    // Stream Codecs
    uint8_t codec_id;
    uint8_t codec_seq;
    uint8_t codec_qual;
};
```


**缺少的字段**:

1. **compressed_total_size**: Block 压缩后的总大小
   - **影响**: 无法快速跳过不需要的 Block
   - **场景**: 随机访问时，需要从 Index 跳转到目标 Block，但不知道中间 Block 的大小

2. **compressed_stream_sizes[]**: 各子流压缩后的大小
   - **影响**: 子流选择性解码时无法确定边界
   - **场景**: `--header-only` 时，只需要解码 ID Stream，但不知道它的大小

**建议修改**:

```cpp
struct BlockHeader {
    uint32_t header_size;
    uint32_t block_id;
    uint8_t checksum_type;
    uint64_t block_xxhash64;
    uint32_t uncompressed_count;
    
    // NEW: Compressed Sizes
    uint32_t compressed_total_size;  // 整个 Block Payload 的压缩大小
    uint32_t compressed_id_size;     // ID Stream 压缩大小
    uint32_t compressed_seq_size;    // Sequence Stream 压缩大小
    uint32_t compressed_qual_size;   // Quality Stream 压缩大小
    uint32_t compressed_aux_size;    // Aux Stream 压缩大小
    
    // Stream Offsets (Relative to Payload Start)
    uint32_t offset_id;
    uint32_t offset_seq;
    uint32_t offset_qual;
    uint32_t offset_aux;
    
    // Stream Codecs
    uint8_t codec_id;
    uint8_t codec_seq;
    uint8_t codec_qual;
};
```

**注意**: 这会增加 Header 大小（+20 bytes），但对于 10K reads/block，overhead 仅 0.002 bytes/read，可以接受。

---

### 2.2 Codec 版本管理过于简化 ⚠️ 低风险

**问题描述**:


当前设计使用 `uint8_t codec_*`，计划用 `(family:4bit, version:4bit)` 编码：

- **问题**: 只有 16 个 family 和 16 个 version 槽位
- **风险**: 对于长期演进（5-10 年），可能不够用
- **例子**: 如果 Sequence Codec 有 SpringABC-v1, SpringABC-v2, Minicom-v1, HARC-v1, LZ4, Zstd, ...，很快会用完

**建议方案**:

```cpp
// 方案 A: 扩展到 16bit
uint16_t codec_seq;  // (family:8bit, version:8bit) = 256 families * 256 versions

// 方案 B: 使用注册表 ID
uint16_t codec_seq;  // 直接映射到全局 Codec Registry
// Registry 定义在文档中，例如：
// 0x0001: SpringABC-v1
// 0x0002: SpringABC-v2
// 0x0101: Minicom-v1
// 0x0201: Zstd-v1
```

推荐**方案 A**，更灵活且易于实现。

---

### 2.3 Block Index 缺少 compressed_size 字段 ⚠️ 中风险

**问题描述**:

当前 Block Index 定义：

```cpp
struct IndexEntry {
    uint64_t offset;           // Block 在文件中的偏移
    uint64_t read_id_start;    // 该 Block 的起始 read ID
};
```

**缺少的字段**: `compressed_size`

**影响**:

1. **无法预分配解压缓冲区**: 解压前不知道需要多大的 buffer
2. **无法并行读取多个 Block**: 不知道 Block 边界，无法同时 seek 到多个位置


**建议修改**:

```cpp
struct IndexEntry {
    uint64_t offset;              // Block 在文件中的偏移
    uint64_t read_id_start;       // 该 Block 的起始 read ID
    uint32_t compressed_size;     // Block 压缩后的大小
    uint32_t uncompressed_count;  // Block 中的 reads 数量
};
```

这样可以支持：

```cpp
// 并行解压多个 Block
std::vector<Block> blocks;
tbb::parallel_for(0, num_blocks, [&](int i) {
    auto& entry = index[i];
    file.seek(entry.offset);
    auto data = file.read(entry.compressed_size);  // 知道大小！
    blocks[i] = decompress(data);
});
```

---

### 2.4 缺少 Magic Footer ⚠️ 低风险

**问题描述**:

当前设计在 File Footer 中有 `MagicEnd: "FQC_EOF"`，但没有说明：

- 是否是固定 8 bytes？
- 是否包含版本号？
- 如何与 `IndexOffset` 和 `GlobalChecksum` 区分？

**建议方案**:

```cpp
struct FileFooter {
    uint64_t index_offset;        // 索引开始位置
    uint64_t global_checksum;     // 全局校验和 (xxhash64)
    uint8_t magic_end[8];         // "FQC_EOF\0" (固定 8 bytes)
};
// Total: 24 bytes
```

这样可以通过 `fseek(file, -24, SEEK_END)` 快速定位 Footer。

---

## 3. 实现计划的问题

### 3.1 Phase 2 风险最高但缺乏 Fallback ⚠️ 高风险

**问题描述**:


Task 7-8（Spring 集成）是整个项目的**关键路径**，但：

- 没有定义"如果 Spring 适配失败"的 Plan B
- 如果在 Phase 2 卡住，整个项目会停滞
- Phase 1 的框架无法独立验证（因为没有实际的压缩算法）

**建议方案**:

**在 Phase 2 之前插入 Phase 1.5: Baseline Implementation**

```markdown
## Phase 1.5: Baseline Compression (插入到 Phase 1 和 Phase 2 之间)

- [ ] 6.5 实现 Baseline 压缩器
  - [ ] 6.5.1 实现简单的 Sequence 压缩器
    - 使用 Zstd 或 LZ4 压缩 Sequence Stream
    - 不做重排序，不做 Assembly
    - 压缩率: ~1.5-2 bits/base (低于 Spring，但可用)
    
  - [ ] 6.5.2 实现简单的 Quality 压缩器
    - 使用 Zstd 压缩 Quality Stream
    - 或使用简单的 Delta + RLE
    
  - [ ] 6.5.3 实现简单的 ID 压缩器
    - 使用 Delta + Zstd
    
  - [ ] 6.5.4 集成到 Pipeline
    - 验证整个框架可以端到端运行
    - 验证格式读写正确性
    - 验证多线程正确性
    
  - [ ] 6.5.5 Checkpoint - Baseline 验证
    - 确保可以压缩和解压 FASTQ 文件
    - 确保 Round-trip Lossless
    - 如果 Phase 2 失败，Baseline 仍可作为最终产品
```

**好处**:

1. **降低风险**: 即使 Spring 集成失败，项目仍有可用的产品
2. **验证框架**: 在投入大量时间到 Spring 之前，先验证框架正确性
3. **增量开发**: 可以先发布 v0.1（Baseline），再发布 v1.0（Spring）

---

### 3.2 属性测试的生成器未定义 ⚠️ 中风险

**问题描述**:


tasks.md 中定义了多个属性测试（Property Tests），例如：

```markdown
- **Property 3: 序列压缩往返一致性**
- *For any* 有效的 DNA 序列集合，压缩后解压应产生等价序列
```

但没有定义"有效的 DNA 序列集合"的生成器（Generator）。

**需要明确的问题**:

1. **序列长度分布**: 固定长度？均匀分布？正态分布？
2. **碱基分布**: 均匀分布？真实数据分布？是否包含 `N`？
3. **质量值范围**: Phred33？Phred64？是否包含非法字符？
4. **特殊情况**: 空序列？超长序列（>10KB）？

**建议方案**:

在 `tests/generators/` 目录下定义生成器：

```cpp
// tests/generators/fastq_generator.h
namespace fqc::test {

// 生成随机 DNA 序列
rc::Gen<std::string> genDNASequence(size_t min_len, size_t max_len) {
    return rc::gen::container<std::string>(
        min_len, max_len,
        rc::gen::element('A', 'C', 'G', 'T', 'N')  // 包含 N
    );
}

// 生成随机质量值
rc::Gen<std::string> genQualityString(size_t len) {
    return rc::gen::container<std::string>(
        len, len,
        rc::gen::inRange('!', '~')  // Phred33: 0-93
    );
}

// 生成完整的 FASTQ Record
rc::Gen<ReadRecord> genReadRecord() {
    return rc::gen::build<ReadRecord>(
        rc::gen::set(&ReadRecord::id, genReadID()),
        rc::gen::set(&ReadRecord::seq, genDNASequence(50, 500)),
        rc::gen::set(&ReadRecord::qual, /* 与 seq 长度匹配 */)
    );
}

}  // namespace fqc::test
```

---

### 3.3 缺少性能基准目标 ⚠️ 中风险

**问题描述**:


设计文档和实现计划都没有定义具体的性能目标，例如：

- 压缩率目标是多少？
- 压缩速度目标是多少？
- 内存使用目标是多少？

**影响**:

- 无法判断实现是否成功
- 无法进行有针对性的优化
- 无法与竞品对比

**建议方案**:

在 requirements.md 中增加 **Non-Functional Requirements** 章节：

```markdown
## Non-Functional Requirements

### Performance Targets

| 指标 | Baseline (Phase 1.5) | Target (Phase 2+) | Stretch Goal |
|------|---------------------|-------------------|--------------|
| **压缩率** (bits/base) | 1.5-2.0 | 0.4-0.6 | 0.3-0.4 |
| **压缩速度** (MB/s/thread) | 50-100 | 20-50 | 10-20 |
| **解压速度** (MB/s/thread) | 200-400 | 100-200 | 50-100 |
| **内存峰值** (GB) | < 2 | < 4 | < 8 |

### Comparison with Existing Tools

| 工具 | 压缩率 (bits/base) | 压缩速度 (MB/s) | 解压速度 (MB/s) |
|------|-------------------|----------------|----------------|
| gzip -9 | ~2.0 | ~20 | ~200 |
| Spring | ~0.3 | ~5 | ~50 |
| repaq | ~0.5 | ~100 | ~200 |
| **fqc (Target)** | **0.4-0.6** | **20-50** | **100-200** |

### Test Dataset

- **SRR000001**: Illumina HiSeq, 100bp PE, 10M reads, ~2GB
- **SRR123456**: NovaSeq, 150bp PE, 100M reads, ~20GB
```

---

### 3.4 缺少 Spike 任务 ⚠️ 高风险

**问题描述**:


当前实现计划直接从 Phase 1 跳到 Phase 2（Spring 集成），没有技术验证（Spike）阶段。

**风险**:

- 可能在 Phase 2 投入大量时间后，发现 Spring 无法适配
- 可能发现 Spring 的压缩率在 Block-local 模式下不如预期

**建议方案**:

**在 Phase 1 之前插入 Phase 0: Technical Spike**

```markdown
## Phase 0: Technical Spike (2-3 天)

目标: 验证关键技术假设，降低 Phase 2 风险。

- [ ] 0.1 Spring 代码分析
  - [ ] 0.1.1 克隆 Spring 仓库，编译运行
  - [ ] 0.1.2 使用 GDB/LLDB 调试，理解核心流程
  - [ ] 0.1.3 识别全局状态和依赖关系
  - [ ] 0.1.4 评估改造难度（1-5 分）
  
- [ ] 0.2 Block-local ABC 原型
  - [ ] 0.2.1 提取 Spring 的 Minimizer Bucketing 代码
  - [ ] 0.2.2 实现简单的 Block-local Reordering
  - [ ] 0.2.3 测试压缩率（与全局模式对比）
  - [ ] 0.2.4 如果压缩率损失 > 50%，考虑 Plan B
  
- [ ] 0.3 决策点
  - [ ] 如果 Spike 成功 → 继续 Phase 1
  - [ ] 如果 Spike 失败 → 切换到 Minicom 或 Baseline-only

- [ ] 0.4 输出文档
  - [ ] 创建 `docs/spike-report.md`
  - [ ] 记录发现的问题和解决方案
  - [ ] 更新 Phase 2 的任务分解
```

---

## 4. 技术选型的问题

### 4.1 Quill 的依赖 ⚠️ 低风险

**问题描述**:

Quill 是优秀的日志库，但它依赖 `fmt` 库。如果项目已经使用 C++20，可以考虑用 `std::format` 减少依赖。


**权衡**:

| 方案 | 优势 | 劣势 |
|------|------|------|
| **Quill** | 极低延迟（纳秒级），异步，功能丰富 | 依赖 fmt，二进制体积较大 |
| **spdlog** | 功能丰富，社区活跃 | 延迟略高于 Quill |
| **std::format + 自定义** | 零依赖，轻量 | 需要自己实现异步、日志轮转等 |

**建议**: 保持 Quill，除非对二进制体积有严格要求。

---

### 4.2 CLI11 vs 其他方案 ⚠️ 低风险

**问题描述**:

CLI11 是优秀的选择，但也可以考虑：

| 方案 | 优势 | 劣势 |
|------|------|------|
| **CLI11** | Header-only，功能丰富，现代 C++ | 编译时间略长 |
| **argparse** (C++17) | 轻量，类似 Python argparse | 功能略少 |
| **Boost.Program_options** | 功能强大，久经考验 | 依赖 Boost，重型 |
| **手写解析** | 零依赖，完全控制 | 开发成本高，易出错 |

**建议**: 保持 CLI11，它是当前最佳选择。

---

### 4.3 Conan vs vcpkg ⚠️ 低风险

**问题描述**:

设计文档选择 Conan 2.x，但也可以考虑 vcpkg：

| 方案 | 优势 | 劣势 |
|------|------|------|
| **Conan 2.x** | 功能强大，支持自定义 recipe | 学习曲线陡峭 |
| **vcpkg** | 简单易用，微软支持 | 包数量略少 |
| **Git Submodules** | 完全控制，无外部依赖 | 手动管理版本，繁琐 |

**建议**: 保持 Conan，但在 README 中提供 vcpkg 的安装说明作为备选。

---

## 5. 遗漏的关键点

### 5.1 错误恢复 ⚠️ 中风险

**问题描述**:


如果压缩过程中断（Ctrl+C / OOM / 磁盘满），当前设计没有：

- 部分写入的 `.fqc` 文件如何处理？
- 是否需要 `.fqc.tmp` + rename 的原子写入？
- 是否需要支持断点续压？

**建议方案**:

1. **原子写入** (推荐):
   ```cpp
   // 写入到临时文件
   FQCWriter writer("output.fqc.tmp");
   writer.write_all();
   writer.finalize();
   
   // 原子重命名
   std::filesystem::rename("output.fqc.tmp", "output.fqc");
   ```

2. **清理临时文件**:
   ```cpp
   // 注册信号处理器
   signal(SIGINT, cleanup_handler);
   signal(SIGTERM, cleanup_handler);
   
   void cleanup_handler(int sig) {
       std::filesystem::remove("output.fqc.tmp");
       exit(1);
   }
   ```

3. **断点续压** (可选，Phase 4+):
   - 在 `.fqc.tmp` 中记录已完成的 Block ID
   - 重启时从最后一个完整 Block 继续
   - 复杂度高，优先级低

---

### 5.2 大文件支持 ⚠️ 中风险

**问题描述**:

设计中多处使用 `uint32_t` 作为偏移/大小：

- `BlockHeader.offset_*` 是 `uint32_t`，最大 4GB
- 如果单个 Block 的 Payload > 4GB，会溢出

**分析**:

- 假设 Block Size = 10K reads，平均 read 长度 = 150bp
- 未压缩大小 = 10K * (150 + 150 + 100) = 4MB
- 压缩后大小 ≈ 0.5MB（压缩率 8:1）
- **结论**: 单个 Block 不太可能超过 4GB

但如果支持长读（PacBio HiFi，10-20KB），可能会有问题。


**建议方案**:

1. **保持 uint32_t，但增加检查**:
   ```cpp
   if (compressed_size > UINT32_MAX) {
       throw FQCException("Block too large, reduce --block-reads");
   }
   ```

2. **或升级到 uint64_t**（更安全）:
   ```cpp
   struct BlockHeader {
       // ...
       uint64_t offset_id;    // 支持超大 Block
       uint64_t offset_seq;
       uint64_t offset_qual;
       uint64_t offset_aux;
   };
   ```
   代价：Header 增加 16 bytes。

---

### 5.3 Streaming 输出的进度显示 ⚠️ 低风险

**问题描述**:

`decompress -o -` 输出到 stdout 时，如何处理进度显示？

- 如果进度也输出到 stdout，会污染数据
- 如果输出到 stderr，用户可能看不到（如果重定向了 stderr）

**建议方案**:

1. **自动检测 stdout 是否是 TTY**:
   ```cpp
   bool is_stdout_tty = isatty(STDOUT_FILENO);
   if (!is_stdout_tty) {
       // 禁用进度显示
       config.show_progress = false;
   }
   ```

2. **进度输出到 stderr**:
   ```bash
   fqc decompress -i input.fqc -o - > output.fq 2> progress.log
   ```

3. **提供 --no-progress 选项**:
   ```bash
   fqc decompress -i input.fqc -o - --no-progress | downstream_tool
   ```

---

### 5.4 多文件输入/输出 (Paired-End) ⚠️ 中风险

**问题描述**:

requirements.md 提到支持 Paired-End，但没有明确输入/输出方式：


**方案 A: 双文件输入，单文件输出** (推荐)

```bash
# 压缩
fqc compress -1 R1.fq -2 R2.fq -o output.fqc

# 解压
fqc decompress -i output.fqc -1 R1.out.fq -2 R2.out.fq
```

**方案 B: 交错格式** (Interleaved)

```bash
# 压缩
fqc compress -i interleaved.fq --interleaved -o output.fqc

# 解压
fqc decompress -i output.fqc -o interleaved.out.fq --interleaved
```

**方案 C: 自动检测**

- 如果输入文件名包含 `_R1_` / `_R2_` 或 `_1.fq` / `_2.fq`，自动识别为 PE
- 自动查找配对文件

**建议**: 实现方案 A（明确），Phase 4 可选支持方案 B。

---

### 5.5 版本兼容性策略 ⚠️ 中风险

**问题描述**:

设计文档提到 `Version` 字段和 `GlobalHeaderSize` 用于前向兼容，但没有明确策略：

- 如果 v2.0 增加了新的压缩算法，v1.0 如何处理？
- 如果 v2.0 修改了 BlockHeader 结构，v1.0 如何处理？

**建议方案**:

1. **语义化版本控制**:
   ```
   Version = (major:4bit, minor:4bit)
   - major 变化：不兼容（例如格式重大变更）
   - minor 变化：向后兼容（例如新增可选字段）
   ```

2. **解码器行为**:
   ```cpp
   if (header.version.major > CURRENT_MAJOR) {
       throw FQCException("Unsupported format version");
   }
   if (header.version.minor > CURRENT_MINOR) {
       LOG_WARNING("File created with newer version, some features may not be supported");
   }
   ```

3. **Codec Registry**:
   - 维护一个 Codec 注册表（文档 + 代码）
   - 遇到未知 Codec 时，报错并提示升级



---

## 6. 文档质量评估

### 6.1 优点

1. **结构清晰**: 分为 requirements, design, tasks, ref 四个文档，职责明确
2. **技术深度**: 对参考项目的分析深入，技术选型有理有据
3. **细节丰富**: 格式定义、CLI 设计都很详细

### 6.2 可改进之处

1. **缺少架构图的实现细节**: Mermaid 图很好，但缺少类图和序列图
2. **缺少性能模型**: 没有内存/CPU/IO 的量化分析
3. **缺少风险评估**: 没有明确列出技术风险和缓解措施

**建议**: 增加以下文档：

- `docs/architecture.md`: 详细的类图、序列图
- `docs/performance-model.md`: 内存/CPU/IO 分析
- `docs/risk-assessment.md`: 风险矩阵和缓解计划

---

## 7. 总结与建议

### 7.1 关键风险矩阵

| 风险 | 影响 | 概率 | 优先级 | 缓解措施 |
|------|------|------|--------|----------|
| Spring 集成失败 | 高 | 中 | **P0** | Phase 0 Spike + Phase 1.5 Baseline |
| Block-local 压缩率低 | 高 | 高 | **P0** | 双模式设计（Fast/Best） |
| 格式设计缺陷 | 中 | 低 | **P1** | 增加 size 字段，扩展 codec 版本 |
| 内存溢出 | 中 | 中 | **P1** | 内存预算配置 + 监控 |
| 性能不达标 | 中 | 中 | **P2** | 定义性能目标 + Benchmark |

### 7.2 优先改进建议

**立即执行** (开发前):

1. ✅ **增加 Phase 0: Technical Spike** - 验证 Spring 集成可行性
2. ✅ **增加 Phase 1.5: Baseline Implementation** - 降低风险
3. ✅ **修改 BlockHeader** - 增加 `compressed_*_size` 字段
4. ✅ **修改 IndexEntry** - 增加 `compressed_size` 字段
5. ✅ **定义性能目标** - 在 requirements.md 中增加 NFR 章节


**Phase 1 期间**:

6. ✅ **定义属性测试生成器** - 在 `tests/generators/` 中实现
7. ✅ **实现原子写入** - 使用 `.tmp` + rename
8. ✅ **增加版本兼容性策略** - 在 design.md 中明确

**Phase 2 期间**:

9. ✅ **实现双模式设计** - Fast (Block-local) + Best (Global)
10. ✅ **对比 Spring 压缩率** - 验证 Block-local 的损失

### 7.3 最终评分

| 维度 | 评分 | 说明 |
|------|------|------|
| **架构设计** | ⭐⭐⭐⭐☆ | 清晰分层，但 Spring 集成风险高 |
| **格式设计** | ⭐⭐⭐⭐☆ | 合理，但缺少部分字段 |
| **实现计划** | ⭐⭐⭐☆☆ | 任务分解详细，但缺乏风险缓解 |
| **技术选型** | ⭐⭐⭐⭐⭐ | 优秀，符合现代 C++ 最佳实践 |
| **文档质量** | ⭐⭐⭐⭐☆ | 详细，但缺少性能模型和风险评估 |
| **总体评分** | ⭐⭐⭐⭐☆ | **4/5 - 优秀，但需要改进风险管理** |

### 7.4 推荐的开发路线图

```
Phase 0: Technical Spike (2-3 天)
  ├─ Spring 代码分析
  ├─ Block-local ABC 原型
  └─ 决策：继续 / 降级 / 放弃

Phase 1: Skeleton & Format (1-2 周)
  ├─ 项目初始化
  ├─ 格式定义（修改后的 BlockHeader/IndexEntry）
  └─ CLI 框架

Phase 1.5: Baseline Implementation (1 周)
  ├─ Zstd-based 压缩器
  ├─ 端到端验证
  └─ Checkpoint: 可用的 v0.1

Phase 2: Spring Integration (2-3 周)
  ├─ Spring 适配层
  ├─ 双模式实现（Fast/Best）
  └─ 压缩率对比验证

Phase 3: TBB Pipeline (1-2 周)
  ├─ 并行流水线
  ├─ 内存管理
  └─ 性能测试

Phase 4: Optimization (1-2 周)
  ├─ IO 优化
  ├─ 长读支持
  └─ PE 支持

Phase 5: Verification (1 周)
  ├─ 完整性验证
  ├─ 集成测试
  └─ 文档完善

Total: 8-12 周
```

---

## 8. 附录

### 8.1 推荐阅读


1. **Spring 论文**: "SPRING: a next-generation compressor for FASTQ data" (Bioinformatics, 2019)
2. **Fqzcomp5 文档**: https://github.com/jkbonfield/fqzcomp
3. **Repaq 论文**: "Repaq: a fast and space-efficient FASTQ compressor" (Bioinformatics, 2021)
4. **TBB 文档**: https://oneapi-src.github.io/oneTBB/
5. **C++20 Concepts**: https://en.cppreference.com/w/cpp/language/constraints

### 8.2 参考实现

如果 Spring 集成遇到困难，可以参考以下简化实现：

1. **Minicom**: 更简单的 minimizer-based assembly
2. **HARC**: 基于哈希的压缩（但内存需求高）
3. **LZ4 + Delta**: 最简单的 baseline

### 8.3 测试数据集

推荐使用以下公开数据集进行测试：

| 数据集 | 类型 | 大小 | 来源 |
|--------|------|------|------|
| SRR000001 | Illumina, 36bp SE | 200MB | NCBI SRA |
| SRR1770413 | Illumina HiSeq, 100bp PE | 2GB | NCBI SRA |
| SRR12345678 | NovaSeq, 150bp PE | 20GB | NCBI SRA |
| PacBio HiFi | PacBio, 10-20KB | 5GB | PacBio 官网 |

### 8.4 联系方式

如有问题或需要进一步讨论，请联系：

- **项目负责人**: [Your Name]
- **技术顾问**: [Advisor Name]
- **GitHub Issues**: [Project URL]

---

**文档版本**: v1.0  
**最后更新**: 2026-01-14  
**评估人**: Kiro AI Assistant  
**状态**: ✅ 评估完成，等待反馈

